# ✏️ Weekly Paper — RAG 구성요소 · 평가 · Agentic RAG 리서치

> 키워드: `#LangChain` `#RAG` `#Evals` `#Agent` `#LangGraph`

---

## 🇶 1) LangChain으로 RAG 시스템을 구축할 때 필요한 주요 구성 요소와 역할

RAG는 한 문장으로 요약하면 이거다:

> **“(내 데이터에서) 찾아오고(Retrieve) → (근거로) 답을 쓰는(Generate) 시스템”**

LangChain에서 흔히 쓰는 RAG 구성요소는 아래 흐름으로 정리된다.

### 1. 데이터 인입(Ingestion)
- **Document Loaders**: PDF/HTML/CSV/웹페이지 등 원천 데이터를 `Document`로 로드  
- **Text Splitters**: 문서를 검색하기 좋은 크기의 **chunk**로 분할 (문단/토큰/슬라이딩 윈도우 등)

> 역할: “검색 가능한 형태로 문서를 ‘정돈’한다.”

### 2. 인덱싱(Indexing)
- **Embeddings**: 텍스트를 벡터로 변환  
- **Vector Store**: 벡터를 저장하고 유사도 검색 지원 (예: FAISS, Chroma 등)
- **Retriever**: “어떻게 검색할지” 전략 캡슐화 (top-k, MMR, multi-query 등)

> 역할: “질문에 맞는 근거 조각을 빠르게 ‘찾아’준다.”

### 3. 질의 처리(Querying)
- **Query rewriting / Expansion (선택)**: 질문을 더 잘 찾도록 재작성(예: multi-query)  
- **Context Builder**: 검색 결과를 정리/필터/재정렬해서 LLM에게 넣을 컨텍스트 구성

> 역할: “찾아온 근거를 ‘쓰일 수 있게’ 정리한다.”

### 4. 생성(Generation)
- **Prompt / System Instructions**: “근거 안에서만 답해라”, “출처를 인용해라” 같은 규칙  
- **LLM**: 최종 답변 생성  
- **Output Parser (선택)**: JSON 스키마/정형 출력 강제, 후처리

> 역할: “근거 기반으로 말하게 하고, 형식을 잡는다.”

### 5. 운영(Production)
- **Caching**: 같은 질문/검색 캐시  
- **Observability / Tracing**: 어떤 chunk가 답변에 쓰였는지 추적  
- **Guardrails**: 안전/금칙어/PII 처리 등

> 역할: “잘 돌아가게 + 재현 가능하게 + 사고 나지 않게”

---

## 🇶 2) RAG 성능 평가 방법 & 독립 평가 vs 종단간 평가 차이

RAG 평가는 보통 **세 층**으로 나뉜다:  
**(1) 검색 품질 → (2) 컨텍스트 품질 → (3) 생성 품질**.

---

### A. 독립 평가(Component / Independent Evaluation)
**Retriever(검색기)**와 **Generator(생성기)**를 **각각 따로** 평가한다.

#### 1) Retriever 평가 지표(예시)
- **Precision@k / Recall@k**: 상위 k개 중 정답 문서 비율 / 정답 문서 중 검색된 비율
- **MRR / nDCG**: “정답이 얼마나 위에 떴는가” (순위 품질)

이런 검색 지표들이 대표적이다.

#### 2) Context 평가(예시)
- **Context relevance**: 가져온 문맥이 질문에 관련 있는지
- **Context coverage**: 답에 필요한 근거가 컨텍스트에 충분히 포함되는지
- **Citation coverage**: 답변이 실제 컨텍스트를 인용/참조하는지(정책에 따라)

#### 장점 / 단점
- ✅ “문제가 검색인지 생성인지” **원인 분석**이 쉬움
- ❌ 실제 사용자 경험(최종답 품질)과 1:1로 안 맞을 수 있음  
(검색은 좋아도 LLM이 안 쓰면 망함)

독립평가가 필요한 이유(투명성, 디버깅 용이성)는 RAG 평가 연구에서도 강조된다.

---

### B. 종단간 평가(End-to-End Evaluation)
“질문 → 검색 → 생성 → 최종 답” 전체를 한 번에 평가한다.

#### 대표 지표/방법
- **Answer correctness**: 정답 정확도(골든 레퍼런스 기반)
- **Faithfulness / Groundedness**: 답이 컨텍스트 근거에 기반하는가
- **Answer relevance**: 질문에 제대로 답했는가
- **Human eval / LLM-as-a-judge**: 사람 평가 또는 LLM 판정(실무에서 많이 씀)

실무에서는 “정답성 + 근거성 + 관련성”을 함께 보자는 흐름이 강하다. 

#### 장점 / 단점
- ✅ 사용자 관점에서 “좋다/별로다”가 바로 보임
- ❌ 왜 별로인지(검색? 프롬프트? 청킹?) **원인 분해가 어렵다**

---

### ✅ 차이를 한 문장으로
> **독립 평가는 “고장 난 부품을 찾는 평가”,  
> 종단간 평가는 “차가 목적지에 잘 가는지 보는 평가”다.**

---

## 🇶 3) RAG에서 ‘Agent’는 무엇이며, 어떻게 구현하나?

### 1) Agent란?
Agent는 단순히 “답변 생성”을 넘어서,
LLM이 **상황을 판단해 도구(tool)를 선택·호출하고**,  
필요하면 여러 번 반복해 목표를 달성하는 실행자다.

- 검색을 한 번만 하는 게 아니라  
  “검색 → 부족함 감지 → 추가 검색/필터 변경 → 요약” 같은 **루프**를 만들 수 있음
- 그래서 요즘은 **Agentic RAG**라는 말도 자주 쓴다(툴 사용 + 다단계 retrieval). 

---

### 2) RAG에서 Agent가 유용한 대표 상황
- 질문이 모호해서 **추가 질문(clarifying)**이 필요한 경우
- 한 번의 검색으로 부족해 **멀티홉 탐색**이 필요한 경우
- 여러 소스(벡터DB + 웹 + 내부DB)를 **상황별로 선택**해야 하는 경우
- 답변 후 “근거 부족”을 감지해 **재검색**해야 하는 경우

---

### 3) LangChain에서의 구현 방식(큰 그림)
- **Tools**: retriever, 웹검색, DB조회, 계산기 등 “행동 목록”
- **Agent**: 어떤 tool을 언제 쓸지 결정하는 LLM 기반 정책
- **Executor/Runtime**: agent가 tool 호출하고 결과를 다시 agent에 넣는 실행 루프

LangChain 문서에서도 Agent는 “모델 노드 + 도구 노드 등을 연결한 실행 흐름”으로 설명되며, 요즘은 그래프 기반 런타임을 적극 권한다. 

---

### 4) LangGraph로 구현하는 이유(요즘 트렌드)
Agent는 “한 번 생각하고 끝”이 아니라 “상태를 가진 반복”이 핵심이라서,  
그래프가 잘 맞는다.

- **Nodes**: LLM 호출, tool 실행, 검증, 재검색 등
- **Edges**: 다음 단계로 넘어가는 규칙(조건부 분기)
- **State**: 대화/중간 결과/근거 목록을 계속 들고 다님

LangGraph는 이런 **사이클/분기/상태**를 공식적으로 다루기 위해 나온 흐름으로 소개된다.

---

## ✅ 전체 요약 한 문장
> **RAG는 “근거를 찾는 시스템”이고,  
> Agentic RAG는 “근거를 찾는 방법을 스스로 바꾸는 시스템”이다.**
