# 📌 이미지 전처리·데이터 증강·전이학습 정리

---

## 🇶 이미지를 모델에 입력하기 전에 리사이징(Resizing)과 정규화(Normalization)를 하는 이유는?

### ✔ Resizing
딥러닝 모델은 **고정된 입력 크기**를 요구한다.  
이미지 크기가 제각각이면 텐서 형태가 달라져서 모델이 처리할 수 없다.  
그래서 모든 이미지를 같은 크기로 맞춰 모델이 읽을 수 있는 **단일한 텐서 형태**로 정리한다.

> 쉽게 말하면, 모델이 “사진 사이즈 통일 좀 해주세요…”라고 외치기 전에 미리 맞춰주는 과정.

### ✔ Normalization  
이미지의 픽셀 값(0~255)을 0~1 또는 -1~1로 **범위를 축소**하는 작업이다.  
이걸 하는 이유는:

- 값의 범위를 줄여 **학습 안정성**을 높이고  
- 그래디언트 폭주/소실을 예방하며  
- 여러 입력 이미지들의 **분포를 비슷하게 맞춰** 모델이 학습하기 쉽게 만드는 것

즉, 정규화는 모델에게  
“과하게 밝거나 어둡지 않은, 안정적인 데이터들만 주세요”  
라고 말해주는 셈이다.

---

## 🇶 데이터 증강(Data Augmentation)이란?  
### 그리고 이미지에서 주로 쓰는 기법들?

### ✔ Data Augmentation 정의
기존 이미지를 인위적으로 변형해 **새 데이터처럼 만드는 기술**.  
사진을 더 찍지 않아도 데이터 개수가 늘어난 효과를 주고,  
과적합(overfitting)을 막아 모델이 더 튼튼해진다.

### ✔ 이미지에서 자주 쓰는 증강 기법

- **Random Horizontal Flip (좌우 반전)**  
  → 개·고양이 좌우 방향이 달라도 인식 가능하게  
- **Random Rotation (회전)**  
  → 약간 돌아간 사진에도 강해지도록  
- **Random Crop / RandomResizedCrop**  
  → 사진 일부만 잘라 모델이 다양한 구도로 학습하도록  
- **Color Jitter (밝기·대비·채도 변화)**  
  → 조명 변화에 흔들리지 않게  
- **Gaussian Blur / Noise**  
  → 사진이 약간 흐리거나 노이즈가 있어도 견디도록  
- **Cutout / Random Erasing**  
  → 일부 영역을 지워도 핵심 특징을 잡아내도록

데이터 증강은 결국  
“세상엔 완벽한 사진이 없다. 그러니 모델도 다양한 상황에 적응하자!”  
라는 철학을 모델에게 심어주는 과정이다.

---

## 🇶 Transfer Learning(전이 학습)이란?  
### 이미지 분류에서 어떻게 활용할까?

### ✔ Transfer Learning 정의
이미 거대한 데이터셋(예: ImageNet)으로 학습된 모델의 **지식을 재활용**해  
새로운 작업에 적용하는 방법.

즉, “이미 세상을 넓게 경험한 모델한테, 우리 문제만 추가로 가르치면 되는” 전략.

### ✔ 왜 활용하는가?
- 처음부터 학습시키는 것보다 **훨씬 빠르고**  
- 적은 데이터로도 **높은 성능**이 나오며  
- 학습 안정성이 뛰어나다  

### ✔ 이미지 분류에서 활용하는 방식

#### 1) **Feature Extractor(특징 추출기)로 사용**
- 사전학습된 모델의 **초반~중반 Layer는 고정(freeze)**  
- 마지막 분류기(FC Layer)만 우리가 원하는 클래스 수에 맞게 교체  
- 빠르고 안정적인 학습

#### 2) **Fine-tuning(부분 미세조정)**
- 전체 Layer 중 **일부만 unfreeze**하고 추가로 학습  
- 더 정밀한 성능이 필요할 때 사용  
- 데이터가 충분하거나, 사전모델과 도메인이 좀 다를 때 효과적
